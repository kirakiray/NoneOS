<template page>
  <l-m src="/packages/pui/list/list.html"></l-m>
  <style>
    :host {
      display: block;
      padding: 16px;
    }
  </style>
  <p>
    本应用是专为 NoneOS 内部应用打造的管理工具，可实现穿透访问外部世界的功能。
  </p>
  <p>
    借助该应用，内部程序不仅能请求外部 API，还能通过代理访问各类外部 AI 接口。
  </p>
  <h5>本地已下载的模型</h5>
  <p-list>
    <o-fill :value="models">
      <p-list-item>
        <n-local-icon
          name="ai-chip"
          slot="prefix"
          style="display: block; margin-right: 6px"
        ></n-local-icon>
        {{ $data.name }}
      </p-list-item>
    </o-fill>
  </p-list>
  <script>
    export default async ({ load }) => {
      return {
        data: {
          val: "123",
          models: [],
        },
        async attached() {
          this.models = await getOllamaModels();
        },
      };
    };

    // let text = "";

    // 使用示例
    // askOllamaStream("/no_think 你是谁？", "qwen3:4b", (chunk) => {
    //   text += chunk;
    //   console.clear();
    //   console.log(text); // 实时输出每个片段
    // });

    async function getOllamaModels() {
      try {
        const response = await fetch("http://localhost:11434/api/tags");
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        const data = await response.json();
        console.log("已下载的模型:", data.models);
        return data.models;
      } catch (error) {
        console.error("获取模型失败:", error);
        return [];
      }
    }

    async function askOllamaStream(prompt, model = "qwen3:4b", callback) {
      try {
        const response = await fetch("http://localhost:11434/api/generate", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            model: model,
            prompt: prompt,
            stream: true,
            options: {
              num_ctx: 2048, // 上下文窗口大小
              temperature: 0.7, // 创造性程度
              repeat_penalty: 1.1,
              num_predict: 512, // 最大生成长度
              // nothink: true, // 启用无思考模式
            },
          }),
        });

        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }

        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let result = "";

        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = decoder.decode(value);
          const lines = chunk.split("\n").filter((line) => line.trim() !== "");

          for (const line of lines) {
            try {
              const parsed = JSON.parse(line);
              result += parsed.response;
              if (callback) callback(parsed.response);
            } catch (e) {
              console.error("Error parsing JSON:", e);
            }
          }
        }

        return result;
      } catch (error) {
        console.error("Error communicating with Ollama:", error);
        return null;
      }
    }
  </script>
</template>
