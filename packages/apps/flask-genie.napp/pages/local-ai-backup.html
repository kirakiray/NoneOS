<template page>
  <link rel="stylesheet" href="../others/public.css" />
  <l-m src="/packages/pui/select/select.html"></l-m>
  <l-m src="../comps/local-ollama-tags.html"></l-m>
  <l-m src="/packages/i18n/localized-content.html"></l-m>
  <l-m src="/packages/pui/switch/switch.html"></l-m>
  <style>
    :host {
      display: block;
      padding: 16px;
    }
  </style>
  <h3>
    <localized-content>
      <span lang="en"> Local AI </span>
      <span lang="cn"> 本地AI </span>
      <span lang="ja"> ローカルのAI </span>
    </localized-content>
  </h3>
  <localized-content>
    <p lang="en">
      Rely on the Ollama interface installed on the local system to enable
      applications in NoneOS to directly call AI capabilities and unlock more
      diverse AI features.
    </p>
    <p lang="cn">
      依托本地系统安装的Ollama接口，让NoneOS内的应用能够直接调用AI能力，解锁更多丰富的AI功能。
    </p>
    <p lang="ja">
      ローカルシステムにインストールされたOllamaインターフェースを利用して、NoneOS内のアプリケーションが直接AI機能を呼び出せるようにし、より多様なAI機能を解放します。
    </p>
  </localized-content>
  <h4>
    <localized-content>
      <span lang="en"> Local Ollama </span>
      <span lang="cn"> 本地Ollama </span>
      <span lang="ja"> ローカルのOllama </span>
    </localized-content>
  </h4>

  <o-if :value="isLocalhost">
    <p-switch sync:value="useLocalArea">
      <localized-content>
        <span lang="cn"> 使用允许跨域访问的Ollama(临时方案) </span>
        <span lang="en">
          Use Ollama with CORS enabled (temporary solution)
        </span>
        <span lang="ja"> CORSを有効にしたOllamaを使用(一時的な解決策) </span>
      </localized-content>
    </p-switch>
  </o-if>
  <o-if :value="useLocalArea === 'on'">
    <p-input
      sync:value="ollamaHost"
      label="Ollama Host"
      style="margin-top: 8px; max-width: 320px"
    ></p-input>
  </o-if>

  <h5>
    <localized-content>
      <span lang="en"> Your AI Assistant </span>
      <span lang="cn"> 你的AI助手 </span>
      <span lang="ja"> あなたのAIアシスタント </span>
    </localized-content>
  </h5>

  <o-if :value="chatError">
    <p style="color: var(--md-sys-color-error)">{{chatError}}</p>
  </o-if>
  <o-else>
    <div style="text-align: center; padding: 16px; max-width: 600px">
      <div
        style="
          color: var(--md-sys-color-primary);
          font-size: 26px;
          font-weight: 600;
          padding-bottom: 16px;
        "
      >
        {{aiSetting?.ollama?.model}}
      </div>
      <o-if :value="chatting && !chatContent">
        <n-local-icon
          name="loading"
          style="display: inline-block"
        ></n-local-icon>
      </o-if>
      <o-else>
        <div>{{chatContent}}</div>
        <o-if :value="!chatting">
          <p-button
            variant="outlined"
            size="small"
            on:click="refreshChat"
            style="margin-top: 8px"
          >
            <localized-content>
              <span lang="en"> Refresh </span>
              <span lang="cn"> 刷新 </span>
              <span lang="ja"> 再ロード </span>
            </localized-content>
          </p-button>
        </o-if>
      </o-else>
    </div>
  </o-else>

  <h5>
    <localized-content>
      <span lang="en"> Local Models </span>
      <span lang="cn"> 本地模型 </span>
      <span lang="ja"> ローカルのモデル </span>
    </localized-content>
  </h5>

  <local-ollama-tags on:change-setting-model="refreshChat"></local-ollama-tags>

  <script>
    export const parent = "./layout.html";

    import {
      localizedObject,
      getLocalized,
    } from "/packages/i18n/localized-object.js";

    export default async ({ load }) => {
      const { getAISetting } = await load("/packages/ai/custom-data.js");
      const aiSetting = await getAISetting();

      const { setOllamaHost, getOllamaHost } = await load(
        "/packages/ai/ollama.js"
      );

      const { ask } = await load("/packages/ai/main.js");

      const { getSetting } = await load("/packages/none-os/setting.js");

      return {
        data: {
          chatContent: "",
          chatting: false,
          chatError: "",
          aiSetting: {},
          isLocalhost: location.host.includes("localhost"),
          useLocalArea: localStorage.getItem("useLocalArea") || "off",
          ollamaHost: await getOllamaHost(),
        },
        watch: {
          useLocalArea(useLocalArea) {
            if (useLocalArea === "off") {
              this.ollamaHost = "";
            }
            localStorage.setItem("useLocalArea", useLocalArea);
          },
          ollamaHost(ollamaHost) {
            setOllamaHost(ollamaHost.trim());
          },
        },
        proto: {
          async refreshChat() {
            this.chatting = true;
            this.chatContent = "";

            const prompt = await getLocalized({
              cn: "你是谁？回答的内容简短一点",
              en: "Who are you? Just answer",
              ja: "あなたは？直接回答してください。",
            });

            try {
              await ask(prompt, {
                onChunk: ({ modelName, responseText, currentToken }) => {
                  this.chatContent = responseText;
                },
              });
            } catch (err) {
              this.chatError = err.message;
            }

            this.chatting = false;
          },
        },
        async attached() {
          this.emit("update-tab", {
            data: "local-ai",
            composed: true,
          });

          this.refreshChat();
          this.aiSetting = aiSetting;
        },
        detached() {
          this.aiSetting = {};
        },
      };
    };
  </script>
</template>
