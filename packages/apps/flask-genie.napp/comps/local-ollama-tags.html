<template component>
  <l-m src="/packages/pui/list/list.html"></l-m>
  <l-m src="/packages/comps/moment-span.html"></l-m>
  <l-m src="/packages/i18n/localized-content.html"></l-m>
  <l-m src="/packages/i18n/localized-object-content.html"></l-m>
  <style>
    :host {
      display: block;
    }
    .hide {
      display: none;
    }

    .item-content {
      display: flex;
      align-items: center;
    }
  </style>

  <o-if :value="!models">
    <localized-content>
      <div lang="cn">
        <p style="color: var(--md-sys-color-error)">
          无法连接到本地Ollama服务，请检查Ollama服务是否已启动，若已启动可尝试重启服务。
        </p>
        <p style="color: var(--md-sys-color-error)">
          若尚未安装Ollama，可访问
          <a href="https://ollama.com/">ollama.com</a> 进行下载和安装。
        </p>
      </div>
      <div lang="en">
        <p style="color: var(--md-sys-color-error)">
          Failed to connect to local Ollama service, please check if the Ollama
          service has been started, if it has been started, please try to
          restart the service.
        </p>
        <p style="color: var(--md-sys-color-error)">
          If you have not installed Ollama yet, you can visit
          <a href="https://ollama.com/">ollama.com</a> to download and install
          it.
        </p>
      </div>
      <div lang="ja">
        <p style="color: var(--md-sys-color-error)">
          ローカルOllamaサービスに接続できませんでした。Ollamaサービスが起動していることを確認してください。起動している場合は、サービスを再起動してください。
        </p>
        <p style="color: var(--md-sys-color-error)">
          Ollamaがまだインストールされていない場合は、
          <a href="https://ollama.com/">ollama.com</a>
          を訪問してダウンロードしてください。
        </p>
      </div>
    </localized-content>
  </o-if>
  <o-else>
    <p-list>
      <o-fill :value="models" fill-key="name">
        <p-list-item collapse-childs="false" button="suffix">
          <n-local-icon
            name="ai-chip"
            slot="prefix"
            style="
              display: block;
              margin-right: 6px;
              font-size: 20px;
              color: var(--md-sys-color-primary);
            "
          ></n-local-icon>
          <div style="display: flex">
            {{ $data.name }}

            <o-if :value="$host.aiSetting?.ollama?.model === $data.name">
              <div
                style="
                  margin-left: 16px;
                  color: var(--md-sys-color-success);
                  font-size: 20px;
                "
              >
                <n-local-icon name="tick-circle"></n-local-icon>
              </div>
            </o-if>
          </div>
          <i toggle-collapse triangle slot="suffix"></i>
          <p-list slot="childs" style="--ladder-left: 16px">
            <p-list-item>
              <div class="item-content">
                <localized-content>
                  <span lang="cn">模型大小</span>
                  <span lang="en">Model size</span>
                  <span lang="ja">モデルサイズ</span>
                </localized-content>
                : {{$host.getFileSize($data.size)}}
              </div>
            </p-list-item>
            <p-list-item>
              <div class="item-content">
                <localized-content>
                  <span lang="cn">下载时间</span>
                  <span lang="en">Download time</span>
                  <span lang="ja">ダウンロード時間</span>
                </localized-content>
                : {{$host.getTime($data.modified_at)}}
              </div>
            </p-list-item>
            <p-list-item> digest: {{$data.digest}} </p-list-item>

            <p-list-item collapse-childs="false" button="suffix">
              Details
              <i toggle-collapse triangle slot="suffix"></i>
              <p-list slot="childs">
                <o-fill :value="$host.getEntries($data.details)">
                  <p-list-item>
                    <div style="display: flex">
                      <span style="color: var(--md-sys-color-normal)">
                        {{$data.name}}
                      </span>
                      : {{$data.value}}
                    </div>
                  </p-list-item>
                </o-fill>
              </p-list>
            </p-list-item>

            <p-list-item>
              <div>
                <p-button
                  size="small"
                  attr:disabled="$host.aiSetting?.ollama?.model === $data.name"
                  on:click="$host.useModel($data)"
                >
                  <o-if :value="$host.aiSetting?.ollama?.model === $data.name">
                    <localized-content>
                      <span lang="cn">已选择该AI助手</span>
                      <span lang="en">Selected AI assistant</span>
                      <span lang="ja">選択されたAIアシスタント</span>
                    </localized-content>
                  </o-if>
                  <o-else>
                    <localized-content>
                      <span lang="cn">设置为默认AI助手</span>
                      <span lang="en">Set as default AI assistant</span>
                      <span lang="ja">デフォルトのAIアシスタントを設定</span>
                    </localized-content>
                  </o-else>
                </p-button>
                <p-button
                  color="error"
                  size="small"
                  on:click="$host.deleteModel($data)"
                >
                  <localized-content>
                    <span lang="cn">删除该模型</span>
                    <span lang="en">Delete model</span>
                    <span lang="ja">モデルを削除</span>
                  </localized-content>
                </p-button>
              </div>
            </p-list-item>
          </p-list>
        </p-list-item>
      </o-fill>
      <o-fill :value="requiredModels">
        <p-list-item
          class:hide="$data.installed"
          collapse-childs="false"
          button="suffix"
        >
          <n-local-icon
            name="ai-chip"
            slot="prefix"
            style="
              display: block;
              margin-right: 6px;
              font-size: 20px;
              color: var(--md-sys-color-normal);
            "
          ></n-local-icon>
          <div style="display: flex; align-items: center">{{$data.name}}</div>
          <i toggle-collapse triangle slot="suffix"></i>
          <p-list slot="childs" style="--ladder-left: 16px">
            <p-list-item>
              <localized-object-content
                :obj="$data.desc"
              ></localized-object-content
            ></p-list-item>
            <p-list-item>
              <div class="item-content">
                <localized-content>
                  <span lang="cn">模型大小</span>
                  <span lang="en">Model size</span>
                  <span lang="ja">モデルサイズ</span>
                </localized-content>
                : {{$data.size}}
                <p-button
                  color="primary"
                  size="small"
                  variant="outlined"
                  on:click="$host.pullModel($data)"
                  attr:disabled="$data.downloading"
                  style="margin-left: 16px"
                >
                  <o-if :value="$data.downloading">
                    <n-local-icon
                      name="loading"
                      style="margin-right: 4px; display: block"
                    ></n-local-icon>
                    <localized-content>
                      <span lang="cn">下载中</span>
                      <span lang="en">Downloading</span>
                      <span lang="ja">ダウンロード中</span>
                    </localized-content>
                  </o-if>
                  <o-else>
                    <localized-content>
                      <span lang="cn">下载</span>
                      <span lang="en">Download</span>
                      <span lang="ja">ダウンロード</span>
                    </localized-content>
                  </o-else>
                </p-button>
              </div>
            </p-list-item>
          </p-list>
        </p-list-item>
      </o-fill>
    </p-list>
  </o-else>
  <script>
    export default async ({ load }) => {
      const { getAISetting } = await load("/packages/ai/custom-data.js");
      const aiSetting = await getAISetting();

      const { getOllamaModels, deleteOllamaModel, pullOllamaModel } =
        await load("/packages/ai/main.js");

      const { toast, confirm } = await load("/packages/pui/util.js");
      const { getLocalized } = await load("/packages/i18n/localized-object.js");

      return {
        tag: "local-ollama-tags",
        data: {
          models: [],
          requiredModels: [
            {
              name: "qwen3:4b-instruct",
              installed: false,
              desc: {
                cn: "Qwen3-4B-Instruct 由阿里通义千问推出，参数量约40亿，专为普通用户设备优化，采用非思考模式，运行速度更快。",
                en: "Qwen3-4B-Instruct, launched by Alibaba Tongyi Qianwen, has approximately 4 billion parameters. It is optimized for ordinary user devices and uses a non-thinking mode for faster operation.",
                ja: "Qwen3-4B-Instructはアリババの通義千問によってリリースされ、約40億のパラメータを持ちます。一般ユーザーのデバイス向けに最適化され、非思考モードを採用しており、より高速に動作します。",
              },
            },
            {
              name: "qwen3:4b",
              installed: false,
              desc: {
                cn: "由阿里通义千问推出的Qwen3-4B-Thinking模型，参数量约40亿，专为普通用户设备优化。该模型采用思考模式，具备更强的推理能力，但处理耗时也相对更长。",
                en: "Qwen3-4B-Thinking model, launched by Alibaba Tongyi Qianwen, has approximately 4 billion parameters. It is optimized for ordinary user devices and uses a thinking mode for stronger reasoning ability, but the processing time is also longer.",
                ja: "Qwen3-4B-Thinking はアリババの通義千問によってリリースされ、約40億のパラメータを持ちます。一般ユーザーのデバイス向けに最適化され、思考モードを採用しており、より強力な推論能力を備えています。しかし、処理時間も相対的に長くなります。",
              },
            },
            {
              name: "gemma3:4b",
              installed: false,
              desc: {
                cn: "Google Gemma 3的4B参数版本，轻量级开源模型，专为高效推理设计，在多语言任务中表现良好",
                en: "Google Gemma 3 4B parameter version, a lightweight open source model, designed for efficient inference, performs well in multi-language tasks",
                ja: "Google Gemma 3 4B パラメーターバージョン、軽量のオープンソースモデル、効率的な推論を設計し、多言語タスクで良好なパフォーマンスを発揮",
              },
              size: "3.3GB",
            },
            {
              name: "gemma3n:e4b",
              installed: false,
              desc: {
                cn: "Gemma 3n 型号专为在笔记本电脑、平板电脑或手机等日常设备上高效执行而设计。",
                en: "Gemma 3n model is designed for efficient execution on daily devices such as laptops, tablets, or smartphones.",
                ja: "Gemma 3n モデルは、ノートブック、タブレット、またはスマートフォンなどの日常的なデバイス上で効率的に実行されるように設計されています。",
              },
              size: "7.5GB",
            },
            {
              name: "gemma3n:e2b",
              installed: false,
              desc: {
                cn: "Gemma 3n 型号专为在笔记本电脑、平板电脑或手机等日常设备上高效执行而设计，相比 e4b 进一步降低了资源消耗。",
                en: "Gemma 3n model is designed for efficient execution on daily devices such as laptops, tablets, or smartphones, with further resource consumption reduction compared to e4b.",
                ja: "Gemma 3n モデルは、ノートブック、タブレット、またはスマートフォンなどの日常的なデバイス上で効率的に実行されるように設計されています。e4b と比較して、さらにリソース消費を低減しています。",
              },
              size: "5.6GB",
            },
            {
              name: "qwen3:30b",
              installed: false,
              desc: {
                cn: "通义千问3的30B参数版本，高性能大语言模型，需要较强计算设备支持，在复杂中文任务上表现优异",
                en: "Qwen3 30B parameter version, a high-performance large language model, requires strong computing device support, performs well on complex Chinese tasks",
                ja: "Qwen3 30B パラメーターバージョン、高性能の大規模言語モデル、強力な計算デバイスを必要とし、複雑な中国語タスクで良好なパフォーマンスを発揮",
              },
              size: "19GB",
            },
          ],
          aiSetting: {},
        },
        proto: {
          useModel(data) {
            this.aiSetting.ollama.model = data.model;

            this.emit("change-setting-model");
          },
          getEntries(data) {
            return Object.entries(data).map(([key, value]) => {
              return {
                name: key,
                value,
              };
            });
          },
          async pullModel(data) {
            if (data.size) {
              const ok = await confirm({
                title: await getLocalized({
                  en: "Confirm Model Download",
                  cn: "确认下载模型",
                  ja: "モデルダウンロードの確認",
                }),
                content: await getLocalized({
                  en: `Are you sure you want to download model ${data.name}? This model will take up ${data.size} of disk space. Please note that once the download starts, it cannot be paused and you must wait for completion before deletion.`,
                  cn: `您确定要下载模型 ${data.name} 吗？该模型将占用 ${data.size} 磁盘空间。请注意，下载一旦开始便无法暂停，需等待下载完成后方可删除。`,
                  ja: `モデル ${data.name} をダウンロードしてもよろしいですか？このモデルは ${data.size} のディスク容量を使用します。ダウンロードが開始されると一時停止できず、完了するまで待つ必要があります。`,
                }),
              });

              if (!ok) {
                return;
              }
            }

            const result = await pullOllamaModel(data.name, (e) => {
              console.log(e);
              data.downloading = true;
            });

            this.refreshModels();
            data.downloading = false;
          },
          async deleteModel(data) {
            const ok = await confirm({
              title: await getLocalized({
                en: "Delete Model",
                cn: "删除模型",
                ja: "モデル削除",
              }),
              content: await getLocalized({
                en: `Are you sure you want to delete model ${data.name}?`,
                cn: `确认删除模型 ${data.name} 吗？`,
                ja: `モデル ${data.name} を削除してもよろしいですか？`,
              }),
            });

            if (!ok) {
              return;
            }

            await deleteOllamaModel(data.name);

            toast({
              content: await getLocalized({
                en: `Successfully deleted ${data.name}`,
                cn: `删除 ${data.name} 成功`,
                ja: `${data.name} を正常に削除しました`,
              }),
              color: "success",
            });

            this.refreshModels();
          },
          getFileSize(size) {
            if (size < 1024) {
              return size + "B";
            }
            if (size < 1024 * 1024) {
              return (size / 1024).toFixed(2) + "KB";
            }
            if (size < 1024 * 1024 * 1024) {
              return (size / 1024 / 1024).toFixed(2) + "MB";
            }
            return (size / 1024 / 1024 / 1024).toFixed(2) + "GB";
          },
          getTime(time) {
            return new Date(time).toLocaleString();
          },
          async refreshModels() {
            try {
              const models = await getOllamaModels();

              this.requiredModels.forEach((e) => {
                e.installed = models.some((m) => m.name === e.name);
              });

              this.models = models;
            } catch (error) {
              this.models = null;
              console.log(error);
            }
          },
        },
        attached() {
          this.refreshModels();
          this.aiSetting = aiSetting;
        },
        detached() {
          this.aiSetting = {};
        },
      };
    };
  </script>
</template>
